p1805_hw1_jc5457
================

# Problem 1

Below we import and clean data from
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with
data import, updates variable names, and selects the columns that will
be used in later parts fo this problem. We update `entry` from `yes` /
`no` to a logical variable. As part of data import, we specify that
`Route` columns 8-11 should be character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

**Read, clean, and combine the Mr./Professor. Trash Wheel sheet** \*
Give reasonable names \* Omit non-dumpster-specific rows \* Round sports
balls and convert into integer, and add a column indicating source of
data \* Combine the two data sets

``` r
MR = read_excel("data/Trash Wheel Collection Data.xlsx", 
                sheet = "Mr. Trash Wheel",
                range = "A2:N550")  %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(sports_balls), 
         source = "Mr. Trash Wheel")

PROF = read_excel("data/Trash Wheel Collection Data.xlsx", 
                  sheet = "Professor Trash Wheel",
                  range = "A2:M97")  %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(year = as.character(year),
         source = "Professor Trash Wheel")

Trash_Wheel = bind_rows(MR, PROF)

sport_ball = filter (
  Trash_Wheel, source == "Mr. Trash Wheel" & year == "2020") %>%
  pull(sports_balls)
```

-   The number of observations in the resulting dataset is 641,
-   Key variables include: dumpster, month, year, date, weight_tons,
    volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered,
    source
-   The total weight of trash collected by Professor Trash Wheel is
    190.12
-   The total number of sports balls collected by Mr. Trash Wheel in
    2020 is 856

# Problem 3

**Clean and merge 3 csv files into a single data frame**

1.  Clean the data in pols-month.csv.

-   Use `separate()` to break up the variable `mon` into integer
    variables `year`, `month`, and `day`;
-   replace month number with month name;
-   create a `president` variable taking values `gop` and `dem`, and
    remove `prez_dem` and `prez_gop`;
-   and remove the `day` variable.

``` r
pols_month = 
  read_csv("data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), "-")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
my.month.name = Vectorize(function(n) c("January", "February", "March", 
                                         "April", "May", "June", "July", 
                                         "August", "September", "October",
                                         "November", "December")[n])

pols_month = 
  mutate(
    pols_month,
    month = str_remove(month, "^0+"),
    month = as.numeric(month), 
    month = my.month.name(month),
    year = as.integer(year),
    president = ifelse(prez_gop == 0, "dem", "gop")
    ) %>% 
  subset(select = -c(day, prez_dem, prez_gop)) 
```

2.  Clean the data in snp.csv using a similar process to the above.

-   For consistency across datasets, arrange according to year and
    month, and organize so that `year` and `month` are the leading
    columns.

``` r
snp = 
  read_csv("data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), "/") %>% 
  mutate(
    month = as.numeric(month),
    year = as.integer(year),
    year = ifelse(year > 90, year + 1900, year + 2000),
    month = my.month.name(month),
    ) %>% 
  subset(select = -day) %>%
  relocate(year, month) %>%
  rename(snp = close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

3.  Tidy the unemployment data so that it can be merged with the
    previous datasets.

-   This process will involve switching from “wide” to “long” format;
-   ensuring that key variables have the same name & values: align month
    name with the pol_month and snp datasets

``` r
unemployment =
  read_csv("data/unemployment.csv") %>% 
  janitor::clean_names() %>%
  rename(January = jan,
         February = feb,
         March = mar,
         April = apr,
         May = may,
         June = jun,
         July = jul,
         August = aug,
         September = sep,
         October = oct,
         November = nov,
         December = dec) %>% 
  mutate(
    year = as.integer(year)
  ) %>%
  pivot_longer(
    January:December,
    names_to = "month",
    values_to = "unemployment"
  ) 
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

4.  Join the datasets by merging `snp` into `pols`, and merging
    `unemployment` into the result.

``` r
pol_snp_unemployment = 
  left_join(pols_month, snp) %>%
  left_join(unemployment) 
```

    ## Joining, by = c("year", "month")
    ## Joining, by = c("year", "month")

**Description of dataset** The `pols_month` dataset has 822 rows and 9
columns. \* The years in this dataset range from 1947 to 2015. \* The
variable `president` include character `gop` and `dem`. \* The variable
`pol_value` ranges from to -.

The `snp` dataset has 787 rows and 3 columns. \* The `year` in this
dataset range from 1991 to 2090. \* The variable `snp` ranges from
17.049999 to 2107.389893.

The `unemployment` dataset has 816 rows and 3 columns. \* The `year` in
this dataset range from 1948 to 2015. \* The variable `snp` ranges from
NA to NA.
